{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img width=\"40%\" src=\"logo/pytorch_logo_2018.svg\" /></p>\n",
    "\n",
    "# Grandmaster Pytorch\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Deep Learning has reignited the public interest in AI. The reason is simple: Deep Learning just works.\n",
    "All of deep learning is computations on tensors, which are generalizations of a matrix that can be indexed in more than 2 dimensions.\n",
    "\n",
    "At its core, the development of Pytorch was aimed at being as similar to Python’s Numpy as possible. Doing so would allow an easy and smooth interaction between regular Python code, Numpy, and Pytorch allowing for faster and easier coding.The most basic building block of any Deep Learning library is the tensor. Tensors are matrix-like data structures very similar in function and properties to Numpy arrays. In fact, for most purposes you can think of them exactly like Numpy arrays. The most important difference between the two is that the implementation of tensors in modern Deep Learning libraries can run on CPU or GPU (very fast)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some functions of pytorch (Look twice how they are working)\n",
    "\n",
    "## TORCH\n",
    "\n",
    "The torch package contains data structures for multi-dimensional tensors and mathematical operations over these are defined. Additionally, it provides many utilities for efficient serializing of Tensors and arbitrary types, and other useful utilities.\n",
    "\n",
    "It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0.\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#### Function 1  :-  torch.cat(tensors, dim=0, out=None)\n",
    "#### Function 2  :-  var.detach().numpy()\n",
    "#### Function 3  :-  torch.eq\n",
    "#### Function 4  :-  torch.topk\n",
    "#### Function 5  :-  torch.Tensor.scatter_(dim,index,src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jovian\n",
      "  Using cached jovian-0.2.14-py2.py3-none-any.whl (83 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 56 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting click\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting pyyaml\n",
      "  Using cached PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting uuid\n",
      "  Using cached uuid-1.30.tar.gz (5.8 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/rajat/anaconda3/envs/Jovin.ml/lib/python3.8/site-packages (from requests->jovian) (2020.4.5.1)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 280 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Building wheels for collected packages: pyyaml, uuid\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp38-cp38-linux_x86_64.whl size=44617 sha256=8bcf63317febaa630b75c3ea9888c128a4b1269bbf9d6dad00e14e22d4b40c1e\n",
      "  Stored in directory: /home/rajat/.cache/pip/wheels/13/90/db/290ab3a34f2ef0b5a0f89235dc2d40fea83e77de84ed2dc05c\n",
      "  Building wheel for uuid (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for uuid: filename=uuid-1.30-py3-none-any.whl size=6500 sha256=636d32f06637b120b84931acf385f58d837aacf1e0dd442eed92fd32359caf52\n",
      "  Stored in directory: /home/rajat/.cache/pip/wheels/1b/6c/cb/f9aae2bc97333c3d6e060826c1ee9e44e46306a178e5783505\n",
      "Successfully built pyyaml uuid\n",
      "Installing collected packages: idna, chardet, urllib3, requests, click, pyyaml, uuid, jovian\n",
      "Successfully installed chardet-3.0.4 click-7.1.2 idna-2.9 jovian-0.2.14 pyyaml-5.3.1 requests-2.23.0 urllib3-1.25.9 uuid-1.30\n"
     ]
    }
   ],
   "source": [
    "# !conda install pytorch cpuonly -c pytorch -y\n",
    "!pip install jovian --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import jovian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1 -   torch.cat(tensors, dim=0, out=None)\n",
    "\n",
    "This function concatenates a given sequence of tensors in the specified dimension and returns the concatenated tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1901,  0.0501, -1.1407,  0.5865,  0.4170, -0.3478],\n",
      "        [ 0.2257,  1.4449,  0.7335,  0.3414,  1.5919, -1.2813],\n",
      "        [ 1.2561,  0.9593,  0.7725,  0.5398,  1.4902,  0.4882]])\n",
      "tensor([[ 1.1901,  0.0501, -1.1407,  0.5865,  0.4170, -0.3478,  1.1901,  0.0501,\n",
      "         -1.1407,  0.5865,  0.4170, -0.3478],\n",
      "        [ 0.2257,  1.4449,  0.7335,  0.3414,  1.5919, -1.2813,  0.2257,  1.4449,\n",
      "          0.7335,  0.3414,  1.5919, -1.2813],\n",
      "        [ 1.2561,  0.9593,  0.7725,  0.5398,  1.4902,  0.4882,  1.2561,  0.9593,\n",
      "          0.7725,  0.5398,  1.4902,  0.4882]])\n",
      "torch.Size([3, 12])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 -\n",
    "\n",
    "a=torch.randn(3,6)\n",
    "print(a)\n",
    "b = torch.cat((a,a),1)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we concatenated the tensor a 2 times along the columns, i.e. vertically, and got a tensor of size (3,12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7555, -0.4025,  0.7515, -1.1585,  0.9173,  1.0772],\n",
      "        [ 0.9502,  0.8114,  1.3975,  1.2235,  0.0610,  0.6074]])\n",
      "tensor([[ 0.4251,  1.0284, -0.9509, -0.8756, -1.0005,  0.7822],\n",
      "        [ 0.1720,  0.3170, -0.8046,  1.0496,  1.9015, -0.9608]])\n",
      "tensor([[-0.7555, -0.4025,  0.7515, -1.1585,  0.9173,  1.0772],\n",
      "        [ 0.9502,  0.8114,  1.3975,  1.2235,  0.0610,  0.6074],\n",
      "        [ 0.4251,  1.0284, -0.9509, -0.8756, -1.0005,  0.7822],\n",
      "        [ 0.1720,  0.3170, -0.8046,  1.0496,  1.9015, -0.9608],\n",
      "        [-0.7555, -0.4025,  0.7515, -1.1585,  0.9173,  1.0772],\n",
      "        [ 0.9502,  0.8114,  1.3975,  1.2235,  0.0610,  0.6074]])\n",
      "torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "a=torch.randn(2,6)\n",
    "b=torch.randn(2,6)\n",
    "print(a)\n",
    "print(b)\n",
    "f = torch.cat((a,b,a),0)\n",
    "print(f)\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we concatenated the tensor a along with tensor b along the rows, i.e. horizontally, and got a tensor of size (6,6).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Got 3 and 2 in dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-209c6d5cda48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 3 and 2 in dimension 0"
     ]
    }
   ],
   "source": [
    "# Example 3 - \n",
    "a=torch.randn(3,5)\n",
    "b=torch.randn(2,5)\n",
    "torch.cat((a,b),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we got an error since for this function to work properly, all the tensors that are being concatenated must either have the same shape(except in the concatenating dimension) or be empty. Here the concatenating dimension is 1, ie. concatenation is happening along the columns. But other than dimension 1, dimension 0 of the two tensors a and b have different shape, i.e. a has a shape of 3 and b has b has a shape of 2. Hence this error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can be used when we need to concatenate 2 or more tensors having the same shape along all the dimensions other than the concatenating dimension or otherwise they must be empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2 - var.detach().numpy()\n",
    "\n",
    "Converting tensor to numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1 - working\n",
    "x = torch.tensor(10.)\n",
    "w=torch.tensor(1.1 , requires_grad=True) # requires_grad is to enable gradient (partial differentation). grad stored in grad object\n",
    "b = torch.tensor(2.4,requires_grad=True)\n",
    "\n",
    "y = w*x+b\n",
    "y.backward()# doing partial differentation\n",
    "\n",
    "z = y.detach().numpy()\n",
    "\n",
    "print(\"z is a :\",z)\n",
    "print(\"Y is a :\" ,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully converting y to a numpy and storing it in z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 - working\n",
    "T3  = torch.tensor([[[1.2,2.3,3.4],\n",
    "                     [12,4.4,4.4]],\n",
    "                    [[1.3,43.4,54.3],\n",
    "                     [1.4,6.7,5.7]]])\n",
    "\n",
    "\n",
    "R = T3.numpy()\n",
    "\n",
    "print(R)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as gradient is not enable to T3 we can directly convert it to numpy by var.numpy() menthod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T3  = torch.tensor([[[1.2,2.3,3.4],\n",
    "                     [12,4.4,4.4]],\n",
    "                    [[1.3,43.4,54.3],\n",
    "                     [1.4,6.7,5.7]]] , )\n",
    "w=torch.tensor(1.5 , requires_grad=True) # requires_grad is to enable gradient (partial differentation). grad stored in grad object\n",
    "b = torch.tensor(2.0,requires_grad=True)\n",
    "\n",
    "M = w*T3+b # multipying 3d matrix and \n",
    "\n",
    "M.backward()\n",
    "\n",
    "Z = M.detach().numpy()\n",
    "\n",
    "print(\"Z is : \", Z)\n",
    "# see the error it's very useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing a 3d mtrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "we need to keep in mind that while working with tensors  with gradient= true , we can't convert those tensors to numpy array directly. First we need to detach them.\n",
    "\n",
    "Grad can be implicitly created only for scalar outputs , while using * to multiplay, not for vectors (multidimensionals),\n",
    "To work with grad in multidimensional data (which is actually in DL and ML) we use \"@\" instead of \"*\" and dimension of features and weights must be same (row *column == column*row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 - torch.eq\n",
    "\n",
    "This function compares each item of a tensor with other tensor and shows 'True' if are equal or False if are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True]) tensor([True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "x = torch.tensor([3,1,2])\n",
    "z = torch.tensor([3,1,2])\n",
    "\n",
    "equal0 = torch.eq(x,z)\n",
    "equal1 = x.eq(z)\n",
    "\n",
    "print(equal0, equal1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see two tensor and using the function we can see that the items are True because are equals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True, False])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "x = torch.tensor([4])\n",
    "z = torch.tensor([7,4,8])\n",
    "\n",
    "equal = torch.eq(x,z)\n",
    "\n",
    "print(equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation about example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7a70d0890f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mequal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking \n",
    "x = torch.tensor([2,4])\n",
    "z = torch.tensor([7,4,8])\n",
    "\n",
    "equal = x.eq(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As other functions this need to have the same size or that one be scalar\n",
    "\n",
    "This function is useful for things like classification and any operation that need to verify how much items are equals to the targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4 - torch.topk()\n",
    "\n",
    "This method takes a torch.tensor() object as input and gives us the top k values in that tensor along the specified dimension.\n",
    "\n",
    "Dimension of 0 means it checks through the first axis of our tensor. Dimension of 1 means it travels through the second axis, i.e the columns.\n",
    "\n",
    "1.dim0/rows/vertical\n",
    "\n",
    "2.dim1/colunns/horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.return_types.topk'>\n",
      "tensor([50.,  4.])\n",
      "torch.return_types.topk(\n",
      "values=tensor([50.,  4.]),\n",
      "indices=tensor([3, 2]))\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "input_tensor = torch.tensor([1., 2.3, 4, 50])\n",
    "\n",
    "topk=torch.topk(input_tensor, k=2, dim=0, largest=True)\n",
    "print(type(topk))\n",
    "print(topk.values)\n",
    "print(topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An input tensor of 4 elements were passed into the topk method. Since our function was parameterized by k=2, it spat out the two largest numbers of the given sequence.\n",
    "\n",
    "Do note the return type of this method. It is infact a namedtuple with the values being one of it's attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4605, -0.4089, -1.0306, -1.3053],\n",
      "        [-0.8003,  0.7183,  1.0178, -0.5894]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 0.4605,  0.7183,  1.0178, -0.5894]]),\n",
       "indices=tensor([[0, 1, 1, 1]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "input_tensor = torch.randn(2, 4)\n",
    "print(input_tensor)\n",
    "torch.topk(input_tensor, k=1, dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, instead of dim 1 we asked for the max value along dimension 0, i.e. rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0619, -0.4959, -0.1715, -3.0361],\n",
      "        [ 0.3415,  0.8184, -0.2808,  0.4547],\n",
      "        [ 0.3345,  0.2954, -0.1911, -0.6493],\n",
      "        [-0.4825, -0.5569, -0.9270,  0.6398],\n",
      "        [-0.9909, -0.0218,  2.3836, -0.9851]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3e7a001cdbbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking \n",
    "input_tensor = torch.randn(5, 4)\n",
    "print(input_tensor)\n",
    "\n",
    "torch.topk(input_tensor, k= 5 , dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a tensor of shape 5 rows and 4 columns. We have asked for the top 5 values along the second dimension, i.e. give me the highest 5 top values for each row.\n",
    "\n",
    "Since we have just 4 values in the second dimension, top 5 values is out of range and torch rightfully complains about t.\n",
    "\n",
    "This is used most typically to extract top k probabilites from our predictions. We would get a B*K tensor, where B is the batch and k are the number of classes for our classification problem.\n",
    "\n",
    "We then set dim=1, and ask, give me the top k classes for each sampple in the batch. The demonstration that failed can be interpreted as askking for top k values where k > number of classes!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5 torch.Tensor.scatter_(dim,index,src)\n",
    "\n",
    "This function writes elements from the src tensor into the self tensor at the indices specified by the index tensor. The parameters are:\n",
    "\n",
    "dim - specifies the axis along which to index in the self tensor\n",
    "\n",
    "index - a tensor that contains the indices along which to scatter. It can either be empty or of the same size as src\n",
    "\n",
    "src - a tensor from which elements are to be scattered in the self tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  tensor([[ 0.3093, -0.9936,  1.1666,  0.2736, -1.6328],\n",
      "        [ 2.4571,  1.6418,  0.8444, -0.9488,  0.9347]])\n",
      "b:  tensor([[ 0.3093,  0.0000,  1.1666, -0.9488,  0.9347],\n",
      "        [ 2.4571, -0.9936,  0.0000,  0.0000, -1.6328],\n",
      "        [ 0.0000,  1.6418,  0.8444,  0.2736,  0.0000]])\n",
      "c:  tensor([[ 0.3093,  0.0000,  1.1666, -0.9488,  0.9347],\n",
      "        [ 2.4571, -0.9936,  0.0000,  0.0000, -1.6328],\n",
      "        [ 0.0000,  1.6418,  0.8444,  0.2736,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - \n",
    "a=torch.randn(2,5)\n",
    "print(\"a: \" ,a)\n",
    "b = torch.zeros(3,5)\n",
    "c = b.scatter_(0,torch.tensor([[0,1,0,2,1],[1,2,2,0,0]]),a)\n",
    "print(\"b: \",b)\n",
    "print(\"c: \",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we have scattered elements from the tensor a into another tensor b which was initially filled with zeros. Scattering of elements happened along the rows, i.e. for each element in a, we specified the row indices(0,1,2 here) to send it to the tensor we are scattering into.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 9., 0.],\n",
       "        [0., 0., 9., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "b=torch.zeros(3,5)\n",
    "b.scatter_(1,torch.tensor([[0],[3],[2]]),9.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, instead of providing a tensor from which elements are to be scattered, we can provide a float value instead to be scattered.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1715,  0.0661,  0.1083,  1.1919, -0.1975],\n",
      "        [-1.0946,  0.9056,  1.1083,  2.2833,  1.4951]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected index [3, 5] to be smaller than self [3, 5] apart from dimension 0 and to be smaller size than src [2, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7236c6dfcf1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected index [3, 5] to be smaller than self [3, 5] apart from dimension 0 and to be smaller size than src [2, 5]"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking \n",
    "a=torch.randn(2,5)\n",
    "print(a)\n",
    "b=torch.zeros(3,5)\n",
    "b.scatter_(0,torch.tensor([[0,1,0,2,1],[1,2,2,0,0],[2,1,1,0,0]]),a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example gave error since the size of index along the dimension in which scattering is to be performed must be less than or equal to the size of src tensor along the same dimension as dim that we are passing as parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can be used when we want to populate a tensor with values from another tensor or with values from a scalar float value at the indices specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In above notebook we have seen only few capabalities of pytorch but litrelly there are tones of possibilites of torch have.I can cover everything here but no use of that because WE spend more time in learning and applying so Pytorch community already have a very aewsome documentation . Check the refrence link below to learn further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "Check some medium they will also help in learning\n",
    "* https://medium.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
